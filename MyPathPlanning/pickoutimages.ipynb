{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pick out Images from ROBOFLOW dataset to use in local model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The purpose of this nodebook it to pick out images containing kayaks and the USV from the large dataset from roboflow to be used in a local model and make it faster to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset directory exists\n"
     ]
    }
   ],
   "source": [
    "dataset_dir=\"./USV_LIR_SEARCH_AND_RESCUE\"\n",
    "# check if the dataset directory exists\n",
    "if not os.path.exists(dataset_dir):\n",
    "    print(\"Dataset directory does not exist\")\n",
    "else:\n",
    "    print(\"Dataset directory exists\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_toCheck =[]\n",
    "dir_toCheck.append(dataset_dir+\"/test/labels\")\n",
    "dir_toCheck.append(dataset_dir+\"/train/labels\")\n",
    "dir_toCheck.append(dataset_dir+\"/train/labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through all text files in the dataset directory and it the first chatacter of a line in file contains a 6 print that file name \n",
    "usv_labels_found=[]\n",
    "\n",
    "for dir in dir_toCheck:\n",
    "   \n",
    "    for file in os.listdir(dir):\n",
    "        if file.endswith(\".txt\"):\n",
    "            with open(dir+\"/\"+file) as f:\n",
    "                for line in f:\n",
    "                    if line[0] == '6':\n",
    "                        usv_labels_found.append(file)\n",
    "                        break\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "print(len(usv_labels_found))\n",
    "#duplicate files\n",
    "duplicates = set([x for x in usv_labels_found if usv_labels_found.count(x) > 1])\n",
    "print(len(duplicates))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through all text files in the dataset directory and it the first chatacter of a line in file contains a 6 print that file name \n",
    "kayak_labels_found=[]\n",
    "\n",
    "for dir in dir_toCheck:\n",
    "   \n",
    "    for file in os.listdir(dir):\n",
    "        if file.endswith(\".txt\"):\n",
    "            with open(dir+\"/\"+file) as f:\n",
    "                \n",
    "                for line in f:\n",
    "                    if line[0] == '1':\n",
    "                    \n",
    "                            kayak_labels_found.append(file)\n",
    "                            break\n",
    "\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4461\n",
      "2142\n"
     ]
    }
   ],
   "source": [
    "print(len(kayak_labels_found))\n",
    "#get duplicates\n",
    "duplicates = set([x for x in kayak_labels_found if kayak_labels_found.count(x) > 1])\n",
    "print(len(duplicates))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select 200 images from kayak \n",
    "kayak_labels_found = np.random.choice(kayak_labels_found, 200, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kayak_labels_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add label and image files into a new directory\n",
    "import shutil\n",
    "\n",
    "\n",
    "# create a new directory to store the images and labels\n",
    "new_dir = \"./USV_KAYAK\"\n",
    "if not os.path.exists(new_dir):\n",
    "    os.mkdir(new_dir)\n",
    "    os.mkdir(new_dir+\"/images\")\n",
    "    os.mkdir(new_dir+\"/labels\")\n",
    "\n",
    "new_dir_images = new_dir+\"/images\"\n",
    "new_dir_labels = new_dir+\"/labels\"\n",
    "\n",
    "\n",
    "\n",
    "# add the images from the dataset to the new directory\n",
    "for file in kayak_labels_found:\n",
    "    #check if file is in train test or valid and add to new directory\n",
    "    if file in os.listdir(dataset_dir+\"/train/labels\"):\n",
    "        #copy\n",
    "        shutil.copy(dataset_dir+\"/train/images/\"+file.replace(\".txt\",\".jpg\"),new_dir_images)\n",
    "        shutil.copy(dataset_dir+\"/train/labels/\"+file,new_dir_labels)\n",
    "    elif file in os.listdir(dataset_dir+\"/test/labels\"):\n",
    "        shutil.copy(dataset_dir+\"/test/images/\"+file.replace(\".txt\",\".jpg\"),new_dir_images)\n",
    "        shutil.copy(dataset_dir+\"/test/labels/\"+file,new_dir_labels)\n",
    "    elif file in os.listdir(dataset_dir+\"/valid/labels\"):\n",
    "        shutil.copy(dataset_dir+\"/valid/images/\"+file.replace(\".txt\",\".jpg\"),new_dir_images)\n",
    "        shutil.copy(dataset_dir+\"/valid/labels/\"+file,new_dir_labels)\n",
    "    else:\n",
    "        print(\"file not found\")\n",
    "\n",
    "# add usv labels and images \n",
    "\n",
    "\n",
    "for file in usv_labels_found:\n",
    "     #check if file is in train test or valid and add to new directory\n",
    "    if file in os.listdir(dataset_dir+\"/train/labels\"):\n",
    "        #copy\n",
    "        shutil.copy(dataset_dir+\"/train/images/\"+file.replace(\".txt\",\".jpg\"),new_dir_images)\n",
    "        shutil.copy(dataset_dir+\"/train/labels/\"+file,new_dir_labels)\n",
    "    elif file in os.listdir(dataset_dir+\"/test/labels\"):\n",
    "        shutil.copy(dataset_dir+\"/test/images/\"+file.replace(\".txt\",\".jpg\"),new_dir_images)\n",
    "        shutil.copy(dataset_dir+\"/test/labels/\"+file,new_dir_labels)\n",
    "    elif file in os.listdir(dataset_dir+\"/valid/labels\"):\n",
    "        shutil.copy(dataset_dir+\"/valid/images/\"+file.replace(\".txt\",\".jpg\"),new_dir_images)\n",
    "        shutil.copy(dataset_dir+\"/valid/labels/\"+file,new_dir_labels)\n",
    "    else:\n",
    "        print(\"file not found\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310\n",
      "310\n"
     ]
    }
   ],
   "source": [
    "list=os.listdir(new_dir_images)\n",
    "print(len(list))\n",
    "list2=os.listdir(new_dir_labels)\n",
    "print(len(list2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
